{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diane-park/TableSnap/blob/main/Data_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enXSAgD1h4P7",
        "outputId": "5da3e25a-c38e-4b0d-d823-d2f8590019f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleansing"
      ],
      "metadata": {
        "id": "OG-CnWeLmuNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "annotations_file_path = '/content/drive/Shareddrives/Deep Learning/Deep Learning CSV/General Table Dataset/train_annotated.csv'\n",
        "folds_file_path = '/content/drive/Shareddrives/Deep Learning/Deep Learning CSV/General Table Dataset/train_folds.csv'\n",
        "\n",
        "# Pull information from annotations and folds csv files\n",
        "annotations = pd.read_csv(annotations_file_path)\n",
        "folds = pd.read_csv(folds_file_path)\n",
        "\n",
        "print(annotations.head())\n",
        "print(folds.head())"
      ],
      "metadata": {
        "id": "ekj1AD6ji4K_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41cf9902-c84f-4a12-c907-081e7e047e43"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   image_id                    bbox  \\\n",
            "0  0101_003  [769, 945, 1301, 2028]   \n",
            "1  0110_099  [269, 1652, 2022, 980]   \n",
            "2  0113_013                     NaN   \n",
            "3  0140_007  [698, 1781, 1083, 290]   \n",
            "4  0146_281  [703, 431, 1041, 1121]   \n",
            "\n",
            "                                       segmentation       area  height  \\\n",
            "0    [[769, 945, 769, 2973, 2070, 2973, 2070, 945]]  2638428.0  3300.0   \n",
            "1  [[269, 1652, 269, 2632, 2291, 2632, 2291, 1652]]  1981560.0  3300.0   \n",
            "2                                               NaN        NaN     NaN   \n",
            "3  [[698, 1781, 698, 2071, 1781, 2071, 1781, 1781]]   314070.0  3300.0   \n",
            "4    [[703, 431, 703, 1552, 1744, 1552, 1744, 431]]  1166961.0  3300.0   \n",
            "\n",
            "    width  bbox_xmin  bbox_ymin  bbox_width  bbox_height  \n",
            "0  2544.0      769.0      945.0      1301.0       2028.0  \n",
            "1  2544.0      269.0     1652.0      2022.0        980.0  \n",
            "2     NaN        NaN        NaN         NaN          NaN  \n",
            "3  2560.0      698.0     1781.0      1083.0        290.0  \n",
            "4  2544.0      703.0      431.0      1041.0       1121.0  \n",
            "   image_id  bbox_count  source  fold\n",
            "0  0101_003           1  marmot     3\n",
            "1  0110_099           1  marmot     0\n",
            "2  0140_007           1  marmot     4\n",
            "3  0146_281           2  marmot     4\n",
            "4  0147_090           2  marmot     4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RKjfXDHVmtDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering for images with a single datatables\n",
        "folds_filtered = folds[folds[\"bbox_count\"] == 1]\n",
        "print(folds_filtered.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp4E7pwZlUP4",
        "outputId": "ead449fc-e0ce-4e10-a976-14f1ad4dc1a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   image_id  bbox_count  source  fold\n",
            "0  0101_003           1  marmot     3\n",
            "1  0110_099           1  marmot     0\n",
            "2  0140_007           1  marmot     4\n",
            "7  0148_271           1  marmot     1\n",
            "8  0148_479           1  marmot     2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# continuing filtering for single datatables using annotated dataset\n",
        "# only need annotations_filtered now, don't need to use folds\n",
        "valid_image_ids = set(folds_filtered[\"image_id\"])\n",
        "\n",
        "annotations_filtered = annotations[annotations[\"image_id\"].isin(valid_image_ids)].copy()\n",
        "\n",
        "print(annotations_filtered.head())\n",
        "print(annotations_filtered.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoZSdmDal4Dy",
        "outputId": "5eec0cea-711f-4732-848f-418fe8a97e12"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    image_id                    bbox  \\\n",
            "0   0101_003  [769, 945, 1301, 2028]   \n",
            "1   0110_099  [269, 1652, 2022, 980]   \n",
            "3   0140_007  [698, 1781, 1083, 290]   \n",
            "12  0148_271  [389, 383, 1766, 1032]   \n",
            "13  0148_479  [932, 425, 1198, 1081]   \n",
            "\n",
            "                                        segmentation       area  height  \\\n",
            "0     [[769, 945, 769, 2973, 2070, 2973, 2070, 945]]  2638428.0  3300.0   \n",
            "1   [[269, 1652, 269, 2632, 2291, 2632, 2291, 1652]]  1981560.0  3300.0   \n",
            "3   [[698, 1781, 698, 2071, 1781, 2071, 1781, 1781]]   314070.0  3300.0   \n",
            "12    [[389, 383, 389, 1415, 2155, 1415, 2155, 383]]  1822512.0  3300.0   \n",
            "13    [[932, 425, 932, 1506, 2130, 1506, 2130, 425]]  1295038.0  3300.0   \n",
            "\n",
            "     width  bbox_xmin  bbox_ymin  bbox_width  bbox_height  \n",
            "0   2544.0      769.0      945.0      1301.0       2028.0  \n",
            "1   2544.0      269.0     1652.0      2022.0        980.0  \n",
            "3   2560.0      698.0     1781.0      1083.0        290.0  \n",
            "12  2544.0      389.0      383.0      1766.0       1032.0  \n",
            "13  2560.0      932.0      425.0      1198.0       1081.0  \n",
            "(1308, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescale bbox values to be in terms of the image width and height instead of pixel value\n",
        "# This will lead to less issues when resizing images during the data loading\n",
        "\n",
        "scaled_bboxes = []\n",
        "for index, row in annotations_filtered.iterrows():\n",
        "  x_min = row['bbox_xmin']\n",
        "  y_min = row['bbox_ymin']\n",
        "  bbox_width = row['bbox_width']\n",
        "  bbox_height = row['bbox_height']\n",
        "\n",
        "  im_width= row[\"width\"]\n",
        "  im_height = row[\"height\"]\n",
        "\n",
        "  # All bbox values are now from 0 to 1\n",
        "  bbox = [x_min/im_width, y_min/im_height, bbox_width/im_width, y_min/im_height]\n",
        "\n",
        "  scaled_bboxes.append(bbox)"
      ],
      "metadata": {
        "id": "pCwmsvVmTt4V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare X and Y variables\n",
        "X = annotations_filtered[\"image_id\"].to_list()\n",
        "Y = scaled_bboxes\n",
        "\n",
        "# Check we have the same number of inputs and labels\n",
        "print(\"Number of samples in X: \", len(X))\n",
        "print(\"Number of samples in X: \", len(Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjGezzNQoe92",
        "outputId": "1c2ad728-2d6f-4f5e-a4c7-ec6689f0251c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in X:  1308\n",
            "Number of samples in X:  1308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing\n",
        "Create 70/15/15 train/val/test splits"
      ],
      "metadata": {
        "id": "OT6oW7suoXB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(1308*0.7)\n",
        "val_size = int(1308*0.9)\n",
        "test_size = int(1308*1)\n",
        "\n",
        "X_train, Y_train = X[:train_size], Y[:train_size]\n",
        "X_val, Y_val = X[train_size:val_size], Y[train_size:val_size]\n",
        "X_test, Y_test = X[val_size:], Y[val_size:]\n",
        "\n",
        "print(\"Number of samples in train set: \", len(X_train))\n",
        "print(\"Number of samples in val set: \", len(X_val))\n",
        "print(\"Number of samples in test set: \", len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud3YvOPnpUgY",
        "outputId": "44aa8d39-c778-4c50-f847-d981df65d311"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in train set:  915\n",
            "Number of samples in val set:  262\n",
            "Number of samples in test set:  131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: create visualizations to see if distribution of placement and col/row numbers are even among splits"
      ],
      "metadata": {
        "id": "1SLmvgMOYFKZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}